airflow:
  enabled: true
  airflow:
    image:
      repository: helxplatform/roger
      tag: "0.6.0"
      pullPolicy: Always
    executor: KubernetesExecutor
    config:
      AIRFLOW__CORE__LOAD_EXAMPLES: "FALSE"
      AIRFLOW__CORE__LOGGING_LEVEL: "INFO"
      AIRFLOW__SCHEDULER__SCHEDULE_AFTER_TASK_EXECUTION: "FALSE"
      # Provide http://<URL to nginx >/<web-prefix>
      AIRFLOW__KUBERNETES__DELETE_WORKER_PODS: "TRUE"
      AIRFLOW__WEBSERVER__BASE_URL: ""
    extraEnv:
      - name: ROGER_ANNOTATION_NORMALIZER
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: normalizer_url
      - name: ROGER_DATA_DIR
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: data_directory
      - name: ROGER_DUG__INPUTS_DATA__SETS
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: input_sets
      - name: ROGER_DUG__INPUTS_DATA__SOURCE
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: data_source
      - name: ROGER_ELASTICSEARCH_HOST
        valueFrom:
          configMapKeyRef:
            name: search-elastic-config
            key: host
      - name: ROGER_ELASTICSEARCH_PASSWORD
        valueFrom:
          secretKeyRef:
            name: search-elastic-secret
            key: password
      - name: ROGER_ELASTICSEARCH_USERNAME
        valueFrom:
          secretKeyRef:
            name: search-elastic-secret
            key: username
      - name: ROGER_REDISGRAPH_HOST
        valueFrom:
          configMapKeyRef:
            name: search-redis-config
            key: host
      - name: ROGER_REDISGRAPH_GRAPH
        valueFrom:
          configMapKeyRef:
            name: search-redis-config
            key: graph
      - name: ROGER_REDISGRAPH_PASSWORD
        valueFrom:
          secretKeyRef:
            name: search-redis-secret
            key: password
      - name: ROGER_REDISGRAPH_PORT
        valueFrom:
          configMapKeyRef:
            name: search-redis-config
            key: port
      - name: ROGER_S3_ACCESS__KEY
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_access_key
      - name: ROGER_S3_BUCKET
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_bucket
      - name: ROGER_S3_HOST
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_host
      - name: ROGER_S3_SECRET__KEY
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_secret_key
      - name: ROGER_KGX_DATA__SETS
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: kgx_data_sets
      - name: ROGER_INDEXING_NODE__TO__ELEMENT__QUERIES_ENABLED
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: node_to_queries_enabled
      - name: ROGER_ELASTICSEARCH_NBOOST__HOST
        value: nboost $ TODO compute this
      - name: ROGER_INDEXING_TRANQL__ENDPOINT
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: tranql_endpoint
        value:
      - name: AIRFLOW__CORE__FERNET_KEY
        valueFrom:
          secretKeyRef:
            # Same as airflow.configSecretsName
            name: airflow-config-secrets
            key: fernet-key
    extraVolumeMounts:
      - name: airflow-data
        mountPath: /opt/airflow/share/data
    extraVolumes:
      - name: airflow-data
        persistentVolumeClaim:
          claimName: search-data

    usersUpdate: true
    configSecretsName: airflow-config-secrets

    # Resource config for all task runner pods.
    kubernetesPodTemplate:
      resources:
        limits:
          ephemeral-storage: 4G
          cpu: 2
          memory: 16G
        requests:
          ephemeral-storage: 4G
          cpu: 2
          memory: 16G

  externalRedis:
    host: ""
    passwordSecret: search-redis-secret
    passwordSecretKey: password

  dags:
    gitSync:
      enabled: true
      repo: "https://github.com/helxplatform/roger.git"
      repoSubPath: "dags"
      branch: "main"
      revision: "HEAD"
      syncWait: 60
  scheduler:
    resources:
      limits:
        cpu: 2
        memory: 4G
      requests:
        cpu: 2
        memory: 4G
  web:
    extraPipPackages:
    - Flask-AppBuilder~=3.2.0
    resources:
      limits:
        cpu: 3
        ephemeral-storage: 1G
        memory: 4G
      requests:
        cpu: 3
        ephemeral-storage: 1G
        memory: 4G

  logs:
    path: /opt/airflow/share/logs
    persistence:
      enabled: true
      storageClass: "" ## WARNING: your StorageClass MUST SUPPORT `ReadWriteMany`
      accessMode: ReadWriteMany
      size: 1Gi

  redis:
    enabled: false

  flower:
    enabled: false

  workers:
    enabled: false

api:
  image:
    repository: helxplatform/dug
    tag: ""
    pullPolicy: IfNotPresent

  appName: webserver
  deployment:
    apiPort: 5551
    apiWorkers: 4
    apiTimeout: 10
    extraEnv: []
    logLevel: INFO
    imagePullSecrets: []
    resources:
      limits:
        cpu: 2
        memory: 2G
      requests:
        cpu: 2
        memory: 2G
  service:
    name: search-api
    type: ClusterIP
    annotations: {}
    apiPort: "5551"
  debug: false

config:
  annotation:
    normalizer_url: http://nn-web-prod-node-normalization-web-service-root.translator.svc.cluster.local:8080/get_normalized_nodes?conflate=false&curie=
  input_sets: "bdc-dbGaP,topmed"
  data_source: "stars"
  kgx_data_sets: "baseline-graph,sparc-kgx"
  node_to_queries_enabled: "false"
  s3:
    host: ""
    bucket: ""
    access_key: ""
    secret_key: ""

elasticsearch:
  sysctlInitContainer:
    enabled: false
  enabled: true
  imageTag: "7.16.1"
  replicas: 1
  # default, maybe we ought to increase this as size increases
  # esJavaOpts: "-Xmx1g -Xms1g"
  esJavaOpts: "-Xmx1g -Xms1g -Dlog4j2.disable.jmx=true -Dlog4j2.formatMsgNoLookups=true"
  extraEnvs:
    - name: ELASTIC_PASSWORD
      valueFrom:
        secretKeyRef:
          name: search-elastic-secret
          key: password
    - name: ELASTIC_USERNAME
      valueFrom:
        secretKeyRef:
          name: search-elastic-secret
          key: username
    - name: LOG4J_FORMAT_MSG_NO_LOOKUPS
      value: "true"

nboost:
  enabled: false

persistence:
  storageClass: ""
  pvcSize: 24Gi

redis:
  enabled: true
  persistence:
    existingClaim: "redis-data"
  usePassword: true
  clusterDomain: cluster.local
  auth:
    existingSecret: search-redis-secret
    existingSecretPasswordKey: password
  image:
    repository: redislabs/redisgraph
    tag: 2.8.4
  master:
    persistence:
      size: 16G
    resources:
      limits:
        cpu: 2
        memory: 15Gi
      requests:
        cpu: 500m
        memory: 12Gi
    command: ""
    readinessProbe:
      enabled: true
      # to make it available ASAP
      periodSeconds: 1
      # spans 25 mins (150 * 10 secs)
      failureThreshold: 1
    livenessProbe:
      # Liveliness probes can be off, since
      # With big cache data to load or sync , redis is alive but
      # responds with LOADING message. to avoid cyclic restarts
      # keeping this off
      enabled: false
    extraFlags:
      - "--loadmodule"
      - "/usr/lib/redis/modules/redisgraph.so"
      - "THREAD_COUNT"
      - "8"
      - "OMP_THREAD_COUNT"
      - "16"
      - "--appendonly"
      - "no"
  replica:
#    replicaCount: 1
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 2
      targetCPU: 100
    persistence:
      size: 16G
    resources:
      limits:
        memory: 15Gi
        cpu: 2
      requests:
        memory: 12Gi
        cpu: 500m
    extraFlags:
      - "--loadmodule"
      - "/usr/lib/redis/modules/redisgraph.so"
      - "THREAD_COUNT"
      - "8"
      - "OMP_THREAD_COUNT"
      - "16"
    readinessProbe:
      enabled: true
      # to make it available ASAP
      periodSeconds: 1
      # Having a lower count will make sure that routing to a replica that
      # is not ready yet to not be routed to.
      failureThreshold: 1
      # make sure its really ready
      successThreshold: 5
    livenessProbe:
      enabled: false


secrets:
  elastic:
    name: search-elastic-secret
    user: elastic
    userKey: username
    passwordKey: password
  redis:
    name: search-redis-secret
    passwordKey: password

tranql:
  enabled: true
  existingRedis:
    host: ""
    port: 6379
    secret: search-redis-secret
    secretPasswordKey: password
  webPrefix: "/tranql"  # TODO this and the one below should be combined
  extraEnv:
    - name: WEB_PATH_PREFIX
      value: "/tranql"
  gunicorn:
    # single worker for now to avoid recomputing of schema per worker
    workerCount: 1
    workerTimeout: 1600
  resources:
    limits:
      cpu: 2
      memory: 2G
    requests:
      cpu: 500m
      memory: 2G
  redis:
    enabled: false
