fullnameOverride: ""
nameOverride: ""
airflow:
  enabled: true
  pgbouncer:
    enabled: false
  airflow:
    dbMigrations:
      enabled: true
      ## if a post-install helm Job should be used (instead of a Deployment)
      ## - [WARNING] setting `true` will NOT work with the helm `--wait` flag,
      ##   this is because post-install helm Jobs run AFTER the main resources become Ready,
      ##   which will cause a deadlock, as other resources require db-migrations to become Ready
      ##
      runAsJob: true
    image:
      repository: containers.renci.org/helxplatform/roger
      tag: "latest"
      pullPolicy: Always
    config:
      AIRFLOW__CORE__LOAD_EXAMPLES: "FALSE"
      AIRFLOW__CORE__LOGGING_LEVEL: "INFO"
      AIRFLOW__SCHEDULER__SCHEDULE_AFTER_TASK_EXECUTION: "FALSE"
      # Provide http://<URL to nginx >/<web-prefix>
      AIRFLOW__KUBERNETES__DELETE_WORKER_PODS: "TRUE"
      AIRFLOW__WEBSERVER__BASE_URL: ""
    configSecretsName: airflow-config-secrets
    executor: KubernetesExecutor
    extraEnv:
      - name: ROGER_ANNOTATION_NORMALIZER
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: normalizer_url
      - name: ROGER_ANNOTATION_ANNOTATOR
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: annotator_url
      - name: ROGER_ANNOTATION_SYNONYM__SERVICE
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: synonymizer_url
      - name: ROGER_DATA_DIR
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: data_directory
      - name: ROGER_DUG__INPUTS_DATA__SETS
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: input_sets
      - name: ROGER_DUG__INPUTS_DATA__SOURCE
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: data_source
      - name: ROGER_ELASTICSEARCH_HOST
        valueFrom:
          configMapKeyRef:
            name: search-elastic-config
            key: host
      - name: ROGER_ELASTICSEARCH_PASSWORD
        valueFrom:
          secretKeyRef:
            name: search-elastic-secret
            key: password
      - name: ROGER_ELASTICSEARCH_USERNAME
        valueFrom:
          secretKeyRef:
            name: search-elastic-secret
            key: username
      - name: ROGER_REDISGRAPH_HOST
        valueFrom:
          configMapKeyRef:
            name: search-redis-config
            key: host
      - name: ROGER_REDISGRAPH_GRAPH
        valueFrom:
          configMapKeyRef:
            name: search-redis-config
            key: graph
      - name: ROGER_REDISGRAPH_PASSWORD
        valueFrom:
          secretKeyRef:
            name: search-redis-secret
            key: password
      - name: ROGER_REDISGRAPH_PORT
        valueFrom:
          configMapKeyRef:
            name: search-redis-config
            key: port
      - name: ROGER_S3_ACCESS__KEY
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_access_key
      - name: ROGER_S3_BUCKET
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_bucket
      - name: ROGER_S3_HOST
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_host
      - name: ROGER_S3_SECRET__KEY
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: s3_secret_key
      - name: ROGER_KGX_DATA__SETS
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: kgx_data_sets
      - name: ROGER_INDEXING_NODE__TO__ELEMENT__QUERIES_ENABLED
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: node_to_queries_enabled
      - name: ROGER_ELASTICSEARCH_NBOOST__HOST
        value: nboost $ TODO compute this
      - name: ROGER_INDEXING_TRANQL__ENDPOINT
        valueFrom:
          configMapKeyRef:
            name: search-data-config
            key: tranql_endpoint
        value:
      - name: AIRFLOW__CORE__FERNET_KEY
        valueFrom:
          secretKeyRef:
            # Same as airflow.configSecretsName
            name: airflow-config-secrets
            key: fernet-key
    extraVolumeMounts:
      - name: airflow-data
        mountPath: /opt/airflow/share/data
    extraVolumes:
      - name: airflow-data
        persistentVolumeClaim:
          claimName: search-data
    kubernetesPodTemplate:
      resources:
        limits:
          cpu: 2
          memory: 16G
        requests:
          cpu: 2
          memory: 16G
    usersUpdate: true
    # Resource config for all task runner pods.
  dags:
    gitSync:
      enabled: true
      repo: "https://github.com/helxplatform/roger.git"
      repoSubPath: "dags"
      branch: "main"
      revision: "HEAD"
      syncWait: 60
  externalRedis:
    host: ""
    passwordSecret: search-redis-secret
    passwordSecretKey: password
  flower:
    enabled: false
  logs:
    path: /opt/airflow/share/logs
    persistence:
      enabled: true
      storageClass: "" ## WARNING: your StorageClass MUST SUPPORT `ReadWriteMany`
      accessMode: ReadWriteMany
      size: 5Gi
  redis:
    enabled: false
  scheduler:
    logCleanup:
      enabled: false
    resources:
      limits:
        cpu: 2
        memory: 4G
      requests:
        cpu: 2
        memory: 4G
  web:
    resources:
      limits:
        cpu: 3
        ephemeral-storage: 1G
        memory: 4G
      requests:
        cpu: 3
        ephemeral-storage: 1G
        memory: 4G
  workers:
    enabled: false
  triggerer:
    enabled: false
api:
  replicas: 4
  image:
    repository: helxplatform/dug
    tag: ""
    pullPolicy: Always
  appName: webserver
  debug: false
  deployment:
    apiPort: 5551
    apiWorkers: 4
    apiTimeout: 10
    extraEnv: []
    logLevel: INFO
    imagePullSecrets: []
    resources:
      limits:
        cpu: 2
        memory: 2G
      requests:
        cpu: 2
        memory: 2G
  service:
    name: search-api
    annotations: {}
    apiPort: "5551"
    port: "5551"
    type: ClusterIP
config:
  annotation:
    normalizer_url: https://nodenormalization-sri.renci.org/get_normalized_nodes?conflate=false&curie=
    annotator_url: https://api.monarchinitiative.org/api/nlp/annotate/entities?min_length=4&longest_only=false&include_abbreviation=false&include_acronym=false&include_numbers=false&content=
    synonymizer_url: https://onto.renci.org/synonyms/
  input_sets: "bdc:v2.0,topmed:v2.0"
  data_source: "stars"
  kgx_data_sets: "baseline-graph,cde-graph"
  node_to_queries_enabled: "false"
  s3:
    host: ""
    bucket: ""
    access_key: ""
    secret_key: ""
elasticsearch:
  # default, maybe we ought to increase this as size increases
  # esJavaOpts: "-Xmx1g -Xms1g"
  enabled: true
  esJavaOpts: "-Xmx6g -Xms6g -Dlog4j2.disable.jmx=true -Dlog4j2.formatMsgNoLookups=true"
  clusterHealthCheckParams: "wait_for_status=green&timeout=1s"
  extraEnvs:
    - name: ELASTIC_PASSWORD
      valueFrom:
        secretKeyRef:
          name: search-elastic-secret
          key: password
    - name: ELASTIC_USERNAME
      valueFrom:
        secretKeyRef:
          name: search-elastic-secret
          key: username
    - name: LOG4J_FORMAT_MSG_NO_LOOKUPS
      value: "true"
  imageTag: "7.16.3"
  maxUnavailable: 0
  replicas: 3
  resources:
    limits:
      cpu: 1
      memory: 8G
    requests:
      cpu: 1
      memory: 8G
  sysctlInitContainer:
    enabled: false

ingress:
  enabled: false
  annotations: 
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-origin: "*"
    nginx.ingress.kubernetes.io/cors-allow-methods: "POST, OPTIONS"
    nginx.ingress.kubernetes.io/cors-allow-headers: "Content-Type"
  hosts:
    - host: chart-example.local
  labels: {}
  paths:
    - path: "/"
      name: ui
      port: 80
      prepend: true
    - path: "/airflow"
      name: web
      port: 8080
      prepend: true
    - path: "/tranql"
      name: tranql
      prepend: true
      port: 8081
  rewrite_paths:
    - path: "/search-api(/|$)(.*)"
      name: api
      port: 5551
      prepend: true
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

persistence:
  storageClass: ""
  pvcSize: 32Gi
redis:
  auth:
    existingSecret: search-redis-secret
    existingSecretPasswordKey: password
  clusterDomain: cluster.local
  enabled: true
  image:
    repository: redislabs/redisgraph
    tag: 2.8.4
  persistence:
    existingClaim: "redis-data"
  usePassword: true
  master:
    persistence:
      size: 24G
    resources:
      limits:
        cpu: 2
        memory: 32Gi
      requests:
        cpu: 1
        memory: 12Gi
    command: ""
    readinessProbe:
      enabled: true
      # to make it available ASAP
      periodSeconds: 1
      # spans 25 mins (150 * 10 secs)
      failureThreshold: 1
    livenessProbe:
      # Liveliness probes can be off, since
      # With big cache data to load or sync , redis is alive but
      # responds with LOADING message. to avoid cyclic restarts
      # keeping this off
      enabled: false
    extraFlags:
      - "--loadmodule"
      - "/usr/lib/redis/modules/redisgraph.so"
      - "THREAD_COUNT"
      - "8"
      - "OMP_THREAD_COUNT"
      - "16"
      - "--appendonly"
      - "no"
  replica:
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 1
      targetCPU: 100
    persistence:
      size: 24G
    resources:
      limits:
        cpu: 2
        memory: 32Gi
      requests:
        cpu: 1
        memory: 12Gi
    extraFlags:
      - "--loadmodule"
      - "/usr/lib/redis/modules/redisgraph.so"
      - "THREAD_COUNT"
      - "8"
      - "OMP_THREAD_COUNT"
      - "16"
    readinessProbe:
      enabled: true
      # to make it available ASAP
      periodSeconds: 1
      # Having a lower count will make sure that routing to a replica that
      # is not ready yet to not be routed to.
      failureThreshold: 1
      # make sure its really ready
      successThreshold: 5
    livenessProbe:
      enabled: false
secrets:
  elastic:
    name: search-elastic-secret
    user: elastic
    userKey: username
    passwordKey: password
  redis:
    name: search-redis-secret
    passwordKey: password
tranql:
  enabled: true
  existingRedis:
    host: ""
    port: 6379
    secret: search-redis-secret
    secretPasswordKey: password
  webPrefix: "/tranql"  # TODO this and the one below should be combined
  extraEnv:
    - name: WEB_PATH_PREFIX
      value: "/tranql"
  gunicorn:
    # -- single worker for now to avoid recomputing of schema per worker
    workerCount: 1
    workerTimeout: 1600
  resources:
    limits:
      cpu: 2
      memory: 2G
    requests:
      cpu: 500m
      memory: 2G
  redis:
    enabled: false
redis-insight:
  # -- Enable/Disable Redis UI
  enabled: false
  # -- Url should be same as public ingress url
  rootUrl: ""

ui:
  enabled: False
  config:
    brand_name: ""
    search:
      enabled: "true"
      ## Escaped search endpoint address eg: https:\/\/example.com\/search-api
      url: ""
    tranql_enabled: "true"
    ## Escaped tranql endpoint address eg: https:\/\/example.com\/tranql
    tranql_url: ""
    workspaces:
      # disable workspaces
      enabled: "false"
    hidden_result_tabs: "cdes"
  image:
    pullPolicy: Always
    repository: containers.renci.org/helxplatform/helx-ui
    tag: v5.0.0
